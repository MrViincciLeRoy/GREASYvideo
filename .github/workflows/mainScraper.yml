name: Simple Manga Scraper

on:
  workflow_dispatch:
    inputs:
      start_page:
        description: 'Starting page'
        required: false
        default: '1'
      max_links:
        description: 'Max links to collect'
        required: false
        default: '1000'

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 120
    
    steps:
    - name: Checkout
      uses: actions/checkout@v4
    
    - name: Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y chromium-browser chromium-chromedriver
        pip install playwright
        playwright install chromium
        playwright install-deps
    
    - name: Run scraper
      run: |
        python Scraper.py --start-page ${{ github.event.inputs.start_page }} --max-links ${{ github.event.inputs.max_links }}
    
    - name: Move to data folder
      run: |
        mkdir -p data
        mv manga_database_*.json data/ || echo "No database file found"
        ls -lh data/
    
    - name: Commit and push
      run: |
        git config user.email "action@github.com"
        git config user.name "GitHub Action"
        git add data/
        git commit -m "Add scraped manga database" || echo "Nothing to commit"
        git push || echo "Nothing to push"
    
    - name: Upload artifact
      uses: actions/upload-artifact@v4
      with:
        name: manga-database
        path: data/*.json
        retention-days: 90
