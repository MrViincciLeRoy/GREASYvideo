name: Manga Database Scraper

on:
  workflow_dispatch:
    inputs:
      start_page:
        description: 'Starting page to scrape from'
        required: false
        default: '1'
      max_links:
        description: 'Maximum number of manga links to collect'
        required: false
        default: '1000'

jobs:
  scrape-manga-database:
    runs-on: ubuntu-latest
    timeout-minutes: 120
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y chromium-browser chromium-chromedriver
    
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install playwright
        playwright install chromium
        playwright install-deps
    
    - name: Run Scraper
      run: |
        echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
        echo "ðŸ•·ï¸  STARTING MANGA SCRAPER"
        echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
        echo "Start Page: ${{ github.event.inputs.start_page }}"
        echo "Max Links: ${{ github.event.inputs.max_links }}"
        echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
        echo ""
        
        python Scraper.py \
          --start-page ${{ github.event.inputs.start_page }} \
          --max-links ${{ github.event.inputs.max_links }}
    
    - name: Find generated database
      id: find_db
      run: |
        DATABASE_FILE=$(ls -t manga_database_*.json 2>/dev/null | head -n 1)
        
        if [ -z "$DATABASE_FILE" ]; then
          echo "âŒ No database file generated!"
          exit 1
        fi
        
        echo "âœ“ Database generated: $DATABASE_FILE"
        echo "DATABASE_FILE=$DATABASE_FILE" >> $GITHUB_ENV
        
        echo ""
        echo "ðŸ“Š Database Statistics:"
        cat > show_stats.py << 'PYEOF'
import json
import sys
with open(sys.argv[1], 'r') as f:
    db = json.load(f)
    meta = db['metadata']
    print(f"  Total manga: {meta['total_manga']}")
    print(f"  Completed: {meta['completed_count']}")
    print(f"  Pending: {meta['pending_count']}")
    print(f"  Last page scraped: {meta['last_page_scraped']}")
    print(f"  Created: {meta['created_at']}")
    print("")
    print("ðŸ“š First 5 manga:")
    for manga in db['manga'][:5]:
        print(f"  {manga['id']}. {manga['title']}")
PYEOF
        python3 show_stats.py "$DATABASE_FILE"
        rm show_stats.py
    
    - name: Move database to data folder
      run: |
        echo ""
        echo "ðŸ“ Moving database to data/ folder..."
        mkdir -p data
        cp "${{ env.DATABASE_FILE }}" data/
        echo "âœ“ Database copied to data/${{ env.DATABASE_FILE }}"
        ls -lh "data/${{ env.DATABASE_FILE }}"
    
    - name: Commit and push database
      run: |
        echo ""
        echo "ðŸ’¾ Committing database to repository..."
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add "data/${{ env.DATABASE_FILE }}"
        
        if git diff --staged --quiet; then
          echo "âš ï¸  No changes to commit"
        else
          git commit -m "ðŸ—ƒï¸ Add manga database: ${{ env.DATABASE_FILE }}" \
                     -m "Scraped ${{ github.event.inputs.max_links }} manga links starting from page ${{ github.event.inputs.start_page }}"
          git push
          echo "âœ… Database committed and pushed to repository!"
        fi
    
    - name: Create latest symlink
      run: |
        cd data
        ln -sf "${{ env.DATABASE_FILE }}" manga_database_latest.json
        git add manga_database_latest.json
        git commit -m "ðŸ”— Update latest database symlink" || echo "No changes"
        git push || echo "Nothing to push"
    
    - name: Upload database artifact
      uses: actions/upload-artifact@v4
      with:
        name: manga-database
        path: data/${{ env.DATABASE_FILE }}
        retention-days: 90
    
    - name: Generate summary
      if: always()
      run: |
        echo "# ðŸ“š Manga Database Scraper Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## Configuration" >> $GITHUB_STEP_SUMMARY
        echo "- **Start Page:** ${{ github.event.inputs.start_page }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Max Links:** ${{ github.event.inputs.max_links }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ -f "data/${{ env.DATABASE_FILE }}" ]; then
          echo "## âœ… Database Created Successfully!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**File:** \`data/${{ env.DATABASE_FILE }}\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          cat > summary_stats.py << 'PYEOF'
import json
import sys
with open(sys.argv[1], 'r') as f:
    db = json.load(f)
    meta = db['metadata']
    print('## Statistics')
    print('')
    print('| Metric | Value |')
    print('|--------|-------|')
    print(f"| Total Manga | {meta['total_manga']:,} |")
    print(f"| Completed | {meta['completed_count']} |")
    print(f"| Pending | {meta['pending_count']:,} |")
    print(f"| Last Page | {meta['last_page_scraped']} |")
    print('')
    print('## Sample Entries (First 10)')
    print('')
    for manga in db['manga'][:10]:
        print(f"{manga['id']}. **{manga['title']}**")
        print(f"   - URL: {manga['url']}")
        print('')
PYEOF
          python3 summary_stats.py "data/${{ env.DATABASE_FILE }}" >> $GITHUB_STEP_SUMMARY
          rm summary_stats.py
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "âœ… Database has been committed to the repository" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ“¥ You can also download it from the artifacts above" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Next Steps" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "1. Use the **Download & Convert Manga to Video** workflow" >> $GITHUB_STEP_SUMMARY
          echo "2. Set \`database_file\` to: \`${{ env.DATABASE_FILE }}\`" >> $GITHUB_STEP_SUMMARY
          echo "3. Choose a manga index to process" >> $GITHUB_STEP_SUMMARY
          echo "4. Select chapter range to process" >> $GITHUB_STEP_SUMMARY
        else
          echo "## âŒ Database Creation Failed" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Check the logs above for errors." >> $GITHUB_STEP_SUMMARY
        fi
